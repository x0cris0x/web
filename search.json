[
  {
    "objectID": "r/r_price.html",
    "href": "r/r_price.html",
    "title": "Dataset Sacramento",
    "section": "",
    "text": "El dataset de Sacramento contiene información sobre viviendas y precios de venta de 932 casas en Sacramento, California. Los datos originales se obtuvieron del sitio web del software SpatialKey. Según su sitio web: «El archivo de transacciones inmobiliarias de Sacramento es una lista de 985 transacciones inmobiliarias en el área de Sacramento, registradas durante un período de cinco días, según lo publicado por el Sacramento Bee». Se utilizó Google para completar los datos faltantes o incorrectos.\nMas información\n\n\n\nlibrary(caret)\nlibrary(ggplot2)\nlibrary(dplyr)\n\nCargar el dataset dentro de la variable datos.\n\ndata(Sacramento)\ndatos  = Sacramento\n\nInformación del dataset\n\n# city: Ciudad donde se encuentra la propiedad (factor).\n# zip: Código postal (factor).\n# beds: Número de habitaciones (numérico).\n# baths: Número de baños (numérico).\n# sqft: Superficie en pies cuadrados (numérico).\n# type: Tipo de propiedad (factor: Residential, Condo, Multi-Family, etc.).\n# price: Precio de venta en dólares (numérico).\n# latitude: Latitud geográfica (numérico).\n# longitude: Longitud geográfica (numérico).\n\n\ndim(datos)\n\n[1] 932   9\n\n\nEl dataset tiene 932 observaciones y 9 variables.\n\nstr(datos)\n\n'data.frame':   932 obs. of  9 variables:\n $ city     : Factor w/ 37 levels \"ANTELOPE\",\"AUBURN\",..: 34 34 34 34 34 34 34 34 29 31 ...\n $ zip      : Factor w/ 68 levels \"z95603\",\"z95608\",..: 64 52 44 44 53 65 66 49 24 25 ...\n $ beds     : int  2 3 2 2 2 3 3 3 2 3 ...\n $ baths    : num  1 1 1 1 1 1 2 1 2 2 ...\n $ sqft     : int  836 1167 796 852 797 1122 1104 1177 941 1146 ...\n $ type     : Factor w/ 3 levels \"Condo\",\"Multi_Family\",..: 3 3 3 3 3 1 3 3 1 3 ...\n $ price    : int  59222 68212 68880 69307 81900 89921 90895 91002 94905 98937 ...\n $ latitude : num  38.6 38.5 38.6 38.6 38.5 ...\n $ longitude: num  -121 -121 -121 -121 -121 ...\n\n\nSe observa que existen variables numéricas y categóricas, la variable a analizar es price, la cual es numérica.\n\nResumen estadístico del dataset\n\nsummary(datos)\n\n             city          zip           beds           baths      \n SACRAMENTO    :438   z95823 : 61   Min.   :1.000   Min.   :1.000  \n ELK_GROVE     :114   z95828 : 45   1st Qu.:3.000   1st Qu.:2.000  \n ROSEVILLE     : 48   z95758 : 44   Median :3.000   Median :2.000  \n CITRUS_HEIGHTS: 35   z95835 : 37   Mean   :3.276   Mean   :2.053  \n ANTELOPE      : 33   z95838 : 37   3rd Qu.:4.000   3rd Qu.:2.000  \n RANCHO_CORDOVA: 28   z95757 : 36   Max.   :8.000   Max.   :5.000  \n (Other)       :236   (Other):672                                  \n      sqft                type         price           latitude    \n Min.   : 484   Condo       : 53   Min.   : 30000   Min.   :38.24  \n 1st Qu.:1167   Multi_Family: 13   1st Qu.:156000   1st Qu.:38.48  \n Median :1470   Residential :866   Median :220000   Median :38.62  \n Mean   :1680                      Mean   :246662   Mean   :38.59  \n 3rd Qu.:1954                      3rd Qu.:305000   3rd Qu.:38.69  \n Max.   :4878                      Max.   :884790   Max.   :39.02  \n                                                                   \n   longitude     \n Min.   :-121.6  \n 1st Qu.:-121.4  \n Median :-121.4  \n Mean   :-121.4  \n 3rd Qu.:-121.3  \n Max.   :-120.6  \n                 \n\n\n\nggplot(Sacramento, aes(x = longitude, y = latitude)) +\n  geom_point(aes(color = price), alpha = 0.7, size = 3) +\n  scale_color_gradient(low = \"yellow\", high = \"red\") +\n  labs(title = \"Mapa de precios de viviendas en Sacramento\",\n       x = \"Longitud\", y = \"Latitud\", color = \"Precio (USD)\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\nEl color indica el precio: amarillo = más barato, rojo = más caro. El gráfico es un Scatterplot geográfico: latitud vs longitud\n\nggplot(Sacramento, aes(x = longitude, y = latitude)) +\n  geom_point(aes(color = price), alpha = 0.7, size = 3) +\n  scale_color_gradient(low = \"yellow\", high = \"red\") +\n  facet_wrap(~ type) +\n  labs(title = \"Mapa de precios por tipo de propiedad\",\n       x = \"Longitud\", y = \"Latitud\", color = \"Precio (USD)\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\nEl color indica el precio: amarillo = más barato, rojo = más caro. El gráfico de latitud vs longitud se divido en 3 categorias: condominio, multifamiliar y residencial\n\nggplot(Sacramento, aes(x = longitude, y = latitude)) +\n  geom_point(aes(color = price, size = beds), alpha = 0.6) +\n  scale_color_gradient(low = \"yellow\", high = \"red\") +\n  labs(title = \"Mapa de precios con tamaño según habitaciones\",\n       x = \"Longitud\", y = \"Latitud\", color = \"Precio (USD)\", size = \"Habitaciones\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\nEl color indica el precio: amarillo = más barato, rojo = más caro. El gráfico de latitud vs longitud, se añadio el tamaño de las habitaciones\n\nggplot(datos, aes(x=price)) +  geom_histogram(color=\"black\", fill=\"lightblue\",\n                                              linetype=\"dashed\")+ xlab(label = \"Precio (USD)\")+\n  labs(title =\"Distribución de log precios de casas\" )\n\n\n\n\n\n\n\n\nDistribución de precios de las viviendas, se ve una asimetría en los datos\n\nggplot(datos, aes(x=log10(price))) +  geom_histogram(color=\"black\", fill=\"lightgreen\",\n                                              linetype=\"dashed\")+ xlab(label = \"Precio (USD)\")+\n  labs(title =\"Distribución de log precios de casas\" )\n\n\n\n\n\n\n\n\nDistribución de log10(Precio) de las viviendas, debido a que existe una asimetría en los datos\n\nggplot(datos) +\n  geom_density(aes(x = log10(price), fill = type), alpha=0.25)+\n  ggtitle(\"Densidad sobre log10(price) de las viviendas\")\n\n\n\n\n\n\n\n\n\nggplot(data=datos,aes(x=log10(price), y=sqft,color=type)) +\n  geom_boxplot() +theme_minimal()+ theme() +\n  ggtitle(\"Boxplot de log10(price) de las viviendas\")\n\n\n\n\n\n\n\n\n\n\n\n\nset.seed(123)\ntrain &lt;- createDataPartition(log10(datos$price), p = 0.8, list = FALSE)\ntrainData &lt;- datos[train, ]\ntestData  &lt;- datos[-train, ]\n\nSe divide el dataset en 80% train y 20% test, se utilizo el log para una mejor distribución de los datos\n\nx_train_Data &lt;- trainData %&gt;% select(-price)\nx_test_Data &lt;- testData %&gt;% select(-price)\n\npreProcValues &lt;- preProcess(x_train_Data, method = c(\"center\", \"scale\"))\ntrainTransformed &lt;- predict(preProcValues, x_train_Data)\ntestTransformed  &lt;- predict(preProcValues, x_test_Data)\n\nSe realiza un escalado y centrado de variables y disminuir la varianza de las variables\n\ntrainTransformed$price &lt;- trainData$price\ntestTransformed$price  &lt;- testData$price\n\nReconstruimos los datasets con la variable objetivo y ademas transformadolo en log10 para un mejor modelado de los datos\n\nset.seed(123)\nctrl &lt;- trainControl(method = \"cv\", number = 5)\n\nRealizamos un cross-validation para evitar el sobreajuste\n\nset.seed(123)\nmethods &lt;- c(\"rf\", \"svmRadial\", \"knn\", \"gbm\")\n\nLos modelos que se van a entrenar son: random forest, svmRadial, k-Nearest Neighbors y Generalized Boosted Models\n\nmodels &lt;- lapply(methods, function(m) {\n  train(price ~ .,\n        data = trainTransformed,\n        method = m,\n        trControl = ctrl,\n        tuneLength = 5,\n        verbose = FALSE)})\n\nSe entreno el modelo con los 4 modelos mas utilizados\n\nnames(models) &lt;- methods\nresults &lt;- resamples(models)\nsummary(results)$statistics\n\n$MAE\n              Min.  1st Qu.   Median     Mean  3rd Qu.      Max. NA's\nrf        49238.18 51598.00 53164.11 53445.53 56602.50  56624.86    0\nsvmRadial 91789.55 92955.09 95152.69 95895.11 98034.69 101543.53    0\nknn       49924.93 56814.36 57146.50 57134.09 59973.65  61811.00    0\ngbm       50253.21 50766.03 52178.14 53445.29 54415.45  59613.60    0\n\n$RMSE\n               Min.   1st Qu.    Median      Mean   3rd Qu.      Max. NA's\nrf         70454.95  71479.84  80554.00  77476.81  80764.17  84131.10    0\nsvmRadial 125715.68 134115.58 134245.84 134809.59 138444.56 141526.26    0\nknn        71110.45  79521.12  84608.08  82789.01  88674.75  90030.63    0\ngbm        69287.99  73344.62  78326.73  76928.29  79544.99  84137.15    0\n\n$Rsquared\n               Min.   1st Qu.    Median      Mean   3rd Qu.      Max. NA's\nrf        0.5987966 0.6300578 0.6643078 0.6620008 0.6895211 0.7273205    0\nsvmRadial 0.3993386 0.4330001 0.4491988 0.4478477 0.4508483 0.5068530    0\nknn       0.5540326 0.6000681 0.6172839 0.6127602 0.6373535 0.6550627    0\ngbm       0.6399544 0.6458829 0.6762382 0.6654302 0.6812276 0.6838476    0\n\n\nResumen de las métricas de MAE, RMSE, Rsquared\n\ndotplot(results)\n\n\n\n\n\n\n\n\nSe observa en la gráfica, tanto el rf como gbm tiene los valores mas bajos de RMSE.\n\nbest_model &lt;- models[[\"rf\"]]\npred_price &lt;- predict(best_model, newdata = testTransformed)\nRMSE(pred_price, testData$price)\n\n[1] 59945.81\n\n\nEn los datos de test se observa que el RMSE es de casi 60000,\n\nimportance &lt;- varImp(best_model, scale = TRUE)\nplot(importance, top = 5)\n\n\n\n\n\n\n\n\nEl gráfico muestra las variables mas importantes, en las que se encuentra sqft, longitude y baths"
  },
  {
    "objectID": "r/r_price.html#cargar-las-librerias-y-el-dataset",
    "href": "r/r_price.html#cargar-las-librerias-y-el-dataset",
    "title": "Dataset Sacramento",
    "section": "",
    "text": "library(caret)\nlibrary(ggplot2)\nlibrary(dplyr)\n\nCargar el dataset dentro de la variable datos.\n\ndata(Sacramento)\ndatos  = Sacramento\n\nInformación del dataset\n\n# city: Ciudad donde se encuentra la propiedad (factor).\n# zip: Código postal (factor).\n# beds: Número de habitaciones (numérico).\n# baths: Número de baños (numérico).\n# sqft: Superficie en pies cuadrados (numérico).\n# type: Tipo de propiedad (factor: Residential, Condo, Multi-Family, etc.).\n# price: Precio de venta en dólares (numérico).\n# latitude: Latitud geográfica (numérico).\n# longitude: Longitud geográfica (numérico).\n\n\ndim(datos)\n\n[1] 932   9\n\n\nEl dataset tiene 932 observaciones y 9 variables.\n\nstr(datos)\n\n'data.frame':   932 obs. of  9 variables:\n $ city     : Factor w/ 37 levels \"ANTELOPE\",\"AUBURN\",..: 34 34 34 34 34 34 34 34 29 31 ...\n $ zip      : Factor w/ 68 levels \"z95603\",\"z95608\",..: 64 52 44 44 53 65 66 49 24 25 ...\n $ beds     : int  2 3 2 2 2 3 3 3 2 3 ...\n $ baths    : num  1 1 1 1 1 1 2 1 2 2 ...\n $ sqft     : int  836 1167 796 852 797 1122 1104 1177 941 1146 ...\n $ type     : Factor w/ 3 levels \"Condo\",\"Multi_Family\",..: 3 3 3 3 3 1 3 3 1 3 ...\n $ price    : int  59222 68212 68880 69307 81900 89921 90895 91002 94905 98937 ...\n $ latitude : num  38.6 38.5 38.6 38.6 38.5 ...\n $ longitude: num  -121 -121 -121 -121 -121 ...\n\n\nSe observa que existen variables numéricas y categóricas, la variable a analizar es price, la cual es numérica.\n\nResumen estadístico del dataset\n\nsummary(datos)\n\n             city          zip           beds           baths      \n SACRAMENTO    :438   z95823 : 61   Min.   :1.000   Min.   :1.000  \n ELK_GROVE     :114   z95828 : 45   1st Qu.:3.000   1st Qu.:2.000  \n ROSEVILLE     : 48   z95758 : 44   Median :3.000   Median :2.000  \n CITRUS_HEIGHTS: 35   z95835 : 37   Mean   :3.276   Mean   :2.053  \n ANTELOPE      : 33   z95838 : 37   3rd Qu.:4.000   3rd Qu.:2.000  \n RANCHO_CORDOVA: 28   z95757 : 36   Max.   :8.000   Max.   :5.000  \n (Other)       :236   (Other):672                                  \n      sqft                type         price           latitude    \n Min.   : 484   Condo       : 53   Min.   : 30000   Min.   :38.24  \n 1st Qu.:1167   Multi_Family: 13   1st Qu.:156000   1st Qu.:38.48  \n Median :1470   Residential :866   Median :220000   Median :38.62  \n Mean   :1680                      Mean   :246662   Mean   :38.59  \n 3rd Qu.:1954                      3rd Qu.:305000   3rd Qu.:38.69  \n Max.   :4878                      Max.   :884790   Max.   :39.02  \n                                                                   \n   longitude     \n Min.   :-121.6  \n 1st Qu.:-121.4  \n Median :-121.4  \n Mean   :-121.4  \n 3rd Qu.:-121.3  \n Max.   :-120.6  \n                 \n\n\n\nggplot(Sacramento, aes(x = longitude, y = latitude)) +\n  geom_point(aes(color = price), alpha = 0.7, size = 3) +\n  scale_color_gradient(low = \"yellow\", high = \"red\") +\n  labs(title = \"Mapa de precios de viviendas en Sacramento\",\n       x = \"Longitud\", y = \"Latitud\", color = \"Precio (USD)\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\nEl color indica el precio: amarillo = más barato, rojo = más caro. El gráfico es un Scatterplot geográfico: latitud vs longitud\n\nggplot(Sacramento, aes(x = longitude, y = latitude)) +\n  geom_point(aes(color = price), alpha = 0.7, size = 3) +\n  scale_color_gradient(low = \"yellow\", high = \"red\") +\n  facet_wrap(~ type) +\n  labs(title = \"Mapa de precios por tipo de propiedad\",\n       x = \"Longitud\", y = \"Latitud\", color = \"Precio (USD)\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\nEl color indica el precio: amarillo = más barato, rojo = más caro. El gráfico de latitud vs longitud se divido en 3 categorias: condominio, multifamiliar y residencial\n\nggplot(Sacramento, aes(x = longitude, y = latitude)) +\n  geom_point(aes(color = price, size = beds), alpha = 0.6) +\n  scale_color_gradient(low = \"yellow\", high = \"red\") +\n  labs(title = \"Mapa de precios con tamaño según habitaciones\",\n       x = \"Longitud\", y = \"Latitud\", color = \"Precio (USD)\", size = \"Habitaciones\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\nEl color indica el precio: amarillo = más barato, rojo = más caro. El gráfico de latitud vs longitud, se añadio el tamaño de las habitaciones\n\nggplot(datos, aes(x=price)) +  geom_histogram(color=\"black\", fill=\"lightblue\",\n                                              linetype=\"dashed\")+ xlab(label = \"Precio (USD)\")+\n  labs(title =\"Distribución de log precios de casas\" )\n\n\n\n\n\n\n\n\nDistribución de precios de las viviendas, se ve una asimetría en los datos\n\nggplot(datos, aes(x=log10(price))) +  geom_histogram(color=\"black\", fill=\"lightgreen\",\n                                              linetype=\"dashed\")+ xlab(label = \"Precio (USD)\")+\n  labs(title =\"Distribución de log precios de casas\" )\n\n\n\n\n\n\n\n\nDistribución de log10(Precio) de las viviendas, debido a que existe una asimetría en los datos\n\nggplot(datos) +\n  geom_density(aes(x = log10(price), fill = type), alpha=0.25)+\n  ggtitle(\"Densidad sobre log10(price) de las viviendas\")\n\n\n\n\n\n\n\n\n\nggplot(data=datos,aes(x=log10(price), y=sqft,color=type)) +\n  geom_boxplot() +theme_minimal()+ theme() +\n  ggtitle(\"Boxplot de log10(price) de las viviendas\")"
  },
  {
    "objectID": "r/r_price.html#modelado",
    "href": "r/r_price.html#modelado",
    "title": "Dataset Sacramento",
    "section": "",
    "text": "set.seed(123)\ntrain &lt;- createDataPartition(log10(datos$price), p = 0.8, list = FALSE)\ntrainData &lt;- datos[train, ]\ntestData  &lt;- datos[-train, ]\n\nSe divide el dataset en 80% train y 20% test, se utilizo el log para una mejor distribución de los datos\n\nx_train_Data &lt;- trainData %&gt;% select(-price)\nx_test_Data &lt;- testData %&gt;% select(-price)\n\npreProcValues &lt;- preProcess(x_train_Data, method = c(\"center\", \"scale\"))\ntrainTransformed &lt;- predict(preProcValues, x_train_Data)\ntestTransformed  &lt;- predict(preProcValues, x_test_Data)\n\nSe realiza un escalado y centrado de variables y disminuir la varianza de las variables\n\ntrainTransformed$price &lt;- trainData$price\ntestTransformed$price  &lt;- testData$price\n\nReconstruimos los datasets con la variable objetivo y ademas transformadolo en log10 para un mejor modelado de los datos\n\nset.seed(123)\nctrl &lt;- trainControl(method = \"cv\", number = 5)\n\nRealizamos un cross-validation para evitar el sobreajuste\n\nset.seed(123)\nmethods &lt;- c(\"rf\", \"svmRadial\", \"knn\", \"gbm\")\n\nLos modelos que se van a entrenar son: random forest, svmRadial, k-Nearest Neighbors y Generalized Boosted Models\n\nmodels &lt;- lapply(methods, function(m) {\n  train(price ~ .,\n        data = trainTransformed,\n        method = m,\n        trControl = ctrl,\n        tuneLength = 5,\n        verbose = FALSE)})\n\nSe entreno el modelo con los 4 modelos mas utilizados\n\nnames(models) &lt;- methods\nresults &lt;- resamples(models)\nsummary(results)$statistics\n\n$MAE\n              Min.  1st Qu.   Median     Mean  3rd Qu.      Max. NA's\nrf        49238.18 51598.00 53164.11 53445.53 56602.50  56624.86    0\nsvmRadial 91789.55 92955.09 95152.69 95895.11 98034.69 101543.53    0\nknn       49924.93 56814.36 57146.50 57134.09 59973.65  61811.00    0\ngbm       50253.21 50766.03 52178.14 53445.29 54415.45  59613.60    0\n\n$RMSE\n               Min.   1st Qu.    Median      Mean   3rd Qu.      Max. NA's\nrf         70454.95  71479.84  80554.00  77476.81  80764.17  84131.10    0\nsvmRadial 125715.68 134115.58 134245.84 134809.59 138444.56 141526.26    0\nknn        71110.45  79521.12  84608.08  82789.01  88674.75  90030.63    0\ngbm        69287.99  73344.62  78326.73  76928.29  79544.99  84137.15    0\n\n$Rsquared\n               Min.   1st Qu.    Median      Mean   3rd Qu.      Max. NA's\nrf        0.5987966 0.6300578 0.6643078 0.6620008 0.6895211 0.7273205    0\nsvmRadial 0.3993386 0.4330001 0.4491988 0.4478477 0.4508483 0.5068530    0\nknn       0.5540326 0.6000681 0.6172839 0.6127602 0.6373535 0.6550627    0\ngbm       0.6399544 0.6458829 0.6762382 0.6654302 0.6812276 0.6838476    0\n\n\nResumen de las métricas de MAE, RMSE, Rsquared\n\ndotplot(results)\n\n\n\n\n\n\n\n\nSe observa en la gráfica, tanto el rf como gbm tiene los valores mas bajos de RMSE.\n\nbest_model &lt;- models[[\"rf\"]]\npred_price &lt;- predict(best_model, newdata = testTransformed)\nRMSE(pred_price, testData$price)\n\n[1] 59945.81\n\n\nEn los datos de test se observa que el RMSE es de casi 60000,\n\nimportance &lt;- varImp(best_model, scale = TRUE)\nplot(importance, top = 5)\n\n\n\n\n\n\n\n\nEl gráfico muestra las variables mas importantes, en las que se encuentra sqft, longitude y baths"
  },
  {
    "objectID": "pb/pb_sap.html",
    "href": "pb/pb_sap.html",
    "title": "Visualización de Datos de SAP BO en Power BI”",
    "section": "",
    "text": "Para este ejemplo se utilizo el Database demo de México 2025, para descargar presione aquí.\nPara conocer sobre las tablas que contiene el demo, como tambien los nombres de cada tabla, descripción y respuesta de las filas se utilizó como referencia la siguiente página web aquí.\nPara el análisis del demo, se utilizo como los siguientes herramientas:\n\nMicrosoft SQL Server\nDocker\nSQLPad\nPower BI\n\n\nPaso 1\nSe descargo el Database demo de México, llamado SBODemoMX.\n\n\nPaso 2\nSe creo el archivo docker-compose.yml para instalar Microsoft SQL Server y SQLPad para la GUI.\n\n\n\nPaso 3\nSe testeo la conexión en SQLPad.\n\n\n\nPaso 4\nSe utilizó la siguiente sintaxis para extraer la información para el análisis en Power BI.\n\n\n\nPaso 5\nSe realizó la conexión entre Power BI y SQL Server.\n\n\n\nPaso 6\nSe realizó el Dashboard de Database demo de México en Power BI. El dashboard puedes descargarlo de aquí."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Heredia T. Cristian M.",
    "section": "",
    "text": "Hola, soy especialista en la extracción, tranformación, modelado y visualización de datos. Entusiasta por las nuevas tecnologías emergentes de Machine Learning, Deep Learning y el Cloud Computing.\nApasionado por el entorno R, Python y Power BI.\n\n\n\n\nContacto\n\n\n\n\n\n\n\n\n Experiencia en proyectos de análisis de datos utilizando R, Python y Power BI, cubriendo todo el ciclo: obtención, limpieza, modelado y visualización. \n He diseñado KPI’s y dashboards interactivos como tambien modelos de machine learning y deep learning para apoyar la toma de decisiones estratégicas. Combino habilidades técnicas con capacidad de comunicar hallazgos de forma clara y visual. \n\n\n\n\n\n\n PORTAFOLIO \n\n\nR\n\n\n\nClasificación con el dataset iris\n Análisis de clasificación en R utilizando el conjunto de datos Iris, donde se entrenaron distintos modelos de aprendizaje automático y se eligió el más preciso para reconocer las especies de flores. \n\n\nClasificación del dataset spam\nAplicación de modelos de clasificación en R sobre el conjunto de datos Spam, evaluando diversos algoritmos de aprendizaje automático y seleccionando el más eficiente para distinguir correos electrónicos legítimos de aquellos considerados no deseados.\n\n\nPredicción de precios en viviendas de Sacramento\nAplicación de técnicas de machine learning en R con el dataset de viviendas de Sacramento, comparando varios algoritmos y seleccionando el más eficaz para predecir los precios de las propiedades.\n\n\n\n\n\nPython\n\n\n\nPredicción de Cargos de Seguros\nAplicación de modelos predictivos frecuentistas y bayesianos para predecir los cargos de seguro en Python sobre el dataset Insurance, evaluando diversos algoritmos con la libreria Scikit-learn y eligiendo el más eficiente para predecir gastos sanitarios. Tambien una app web para predecir los cargos.\n\n\nClasificación de depósito al banco\nAplicación de técnicas de machine learning en Python con la libreria de scikit-learn en el dataset Bank Marketing, comparando varios algoritmos y seleccionando el más eficaz para clasificar la suscripción de depósitos.\n\n\nAnálisis temporal del CO₂ de 1958-2021\nAnálisis de series temporales sobre el dataset de concentraciones de CO₂ desde 1958 a 2021, utilizando Python para modelar y pronosticar tendencias futuras.\n\n\n\n\n\nPower BI\n\n\n\nDashboard del COVID-19\nDashboard interactivo en Power BI para el análisis de datos de COVID-19, mostrando el total de casos confirmados, fallecidos y recuperados, así como el incremento en las últimas 24 horas. El panel incluye funcionalidades de filtrado por país, permitiendo una visualización dinámica y comparativa de la evolución de la pandemia a nivel global y regional.\n\n\nDashboard de proyección de financiera\nDashboard financiero en Power BI para el análisis diario de proyecciones económicas, comparando valores reales frente a proyecciones estimadas. El panel incluye intervalos de tiempo configurables y muestra la variación entre ambos escenarios, permitiendo identificar desviaciones y tendencias.\n\n\nDashboard de fitness\nDashboard financiero en Power BI para el análisis diario de proyecciones económicas, comparando valores reales frente a proyecciones estimadas. El panel incluye intervalos de tiempo configurables y muestra la variación entre ambos escenarios, permitiendo identificar desviaciones y tendencias.\n\n\nDashboard de Recursos Humanos\nDashboard de Recursos Humanos en Power BI para la evaluación de desempeño y análisis de sueldos. El reporte integra información clave sobre la fuerza laboral, incluyendo el total de empleados por departamento y métricas comparativas de rendimiento.\n\n\n\n\nPower BI – SAP BO\nConexión de Power BI y SAP Business One: Dashboard de un Database de SAP BO, utilizando Power BI para generar visualizaciones interactivas.\n\n\n\n\n\n\n\n\n\nAplicaciones Web\n\n\n\nTranscripción de Videos/audios\nAplicación Web desarrollado con Pytorch/Whisper, que transcribe videos/audios en inglés.\nNota: Al ingresar te saldra una página de advertencia, debes hacer clíck en el boton “Visite site”.\n\n\nAplicación web sobre la tabla de crecimiento infantil\nAplicación Web dinámica desarrollada con R(shiny) para determinar el crecimiento infantil en menores de 5 años de la OMS.\n\n\nAplicación web sobre regresión lineal\nAplicación Web dinámica desarrollada con R(shiny) para modelar el dataset de Swiss, sobre la fertilidad y indicadores socioeconomicos.\n\n\nAplicación web de Texto predictivo\nAplicación Web dinámica desarrollada con R(shiny) que predice la palabra que vendra después, basándose en el contexto de tu frase. En inglés.\n\n\n\n\n\nAplicaciones Móviles\n\n\n\nAplicación móvil para la evaluación nutricional\nAplicación móvil desarrollada en Flutter para evaluar el estado nutricional de diferentes poblaciones y su crecimiento en menores de 18 años. Se Tomo de referencias la información de la OMS.\n\n\nAplicación móvil predicción de precios\nAplicación móvil creado con Flutter para predecir precios de los inmuebles, se utilizo modelos de machine learning.\n\n\n\n\n\nTableau\n\n\n\nDashboard de aerolíneas\nDashboard diseñado con tableau, el objetivo es analizar el comportamiento de los retrasos en vuelos comerciales.\n\n\n\n\n\n\n\n\nContacto\nCel: (+591)-79391176\nCorreo: cristianvoice@gmail.com"
  },
  {
    "objectID": "p/p_web_regre/p_regre_onnx.html",
    "href": "p/p_web_regre/p_regre_onnx.html",
    "title": "Analisis del dataset de insurance",
    "section": "",
    "text": "Analisis del dataset de insurance\nEl dataset de insurance es un conjunto de datos clásico utilizado para modelar costos médicos en función de características demográficas y de estilo de vida. Contiene información sobre asegurados y el monto de sus gastos médicos, lo que lo hace ideal para practicar modelos de regresión.\nPuedes probar el modelo insertando nuevos datos Aquí\n\nCargar librerias\nimport seaborn as sns\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport shap\n\nfrom sklearn.model_selection import train_test_split, GridSearchCV, KFold\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.metrics import mean_absolute_error, r2_score, root_mean_squared_error\n\nfrom sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet, BayesianRidge, ARDRegression\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, ExtraTreesRegressor, HistGradientBoostingRegressor\nfrom sklearn.neighbors import KNeighborsRegressor\n\nfrom skl2onnx import convert_sklearn\nfrom skl2onnx.common.data_types import FloatTensorType\nimport onnxruntime as ort\n\n\n1 Carga de Datos\ndf = pd.read_csv(\"insurance.csv\")\ndf.head(3)\n\n\n\n\n\n\n\n\nage\n\n\nsex\n\n\nbmi\n\n\nchildren\n\n\nsmoker\n\n\nregion\n\n\ncharges\n\n\n\n\n\n\n0\n\n\n19\n\n\nfemale\n\n\n27.90\n\n\n0\n\n\nyes\n\n\nsouthwest\n\n\n16884.9240\n\n\n\n\n1\n\n\n18\n\n\nmale\n\n\n33.77\n\n\n1\n\n\nno\n\n\nsoutheast\n\n\n1725.5523\n\n\n\n\n2\n\n\n28\n\n\nmale\n\n\n33.00\n\n\n3\n\n\nno\n\n\nsoutheast\n\n\n4449.4620\n\n\n\n\n\nage: Edad del asegurado (numérica).\nsex: Género del asegurado (male, female).\nbmi: Índice de masa corporal (numérica).\nchildren: Número de hijos/dependientes cubiertos por el seguro.\nsmoker: Si el asegurado fuma (yes, no).\nregion: Región geográfica en EE. UU. (northeast, northwest, southeast, southwest).\ncharges: Costos médicos individuales facturados por el seguro (variable objetivo).\n\n\n2 Análisis Exploratorio de Datos\ndf.info()\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 1338 entries, 0 to 1337\nData columns (total 7 columns):\n #   Column    Non-Null Count  Dtype  \n---  ------    --------------  -----  \n 0   age       1338 non-null   int64  \n 1   sex       1338 non-null   object \n 2   bmi       1338 non-null   float64\n 3   children  1338 non-null   int64  \n 4   smoker    1338 non-null   object \n 5   region    1338 non-null   object \n 6   charges   1338 non-null   float64\ndtypes: float64(2), int64(2), object(3)\nmemory usage: 73.3+ KB\nSon 1337 observaciones y 7 variables\ndf.isna().sum()\nage         0\nsex         0\nbmi         0\nchildren    0\nsmoker      0\nregion      0\ncharges     0\ndtype: int64\nNo hay valores Faltantes\ncategoricas = [\"sex\", \"smoker\", \"region\"]\nnumericas = [\"age\", \"bmi\", \"children\", \"charges\"]\nSeparación de la variables categorias y las númericas\nplt.figure(figsize=(5,4))\nfor i, col in enumerate(numericas, 1):\n    plt.subplot(2, 2, i)\n    sns.histplot(df[col], bins=20, kde=True, color='skyblue')\n    plt.title(f'Distribución de {col}')\nplt.tight_layout();\n\n\n\npng\n\n\nHistograma de las 4 variable numericas\nfig, axes = plt.subplots(1, 3, figsize=(12,4))\n\nfor ax, col in zip(axes, categoricas):\n    sns.countplot(x=col, data=df, ax=ax, hue=col)\n    ax.set_title(f'Distribución de {col}')\n    ax.set_xlabel(col)\n    ax.set_ylabel('Frecuencia')\n\nplt.tight_layout();\n\n\n\npng\n\n\nDistribución de las 3 variables categoricas\nfig, axes = plt.subplots(1, 3, figsize=(16,4))\n\nfor ax, col in zip(axes, categoricas):\n    sns.histplot(data=df, x='charges', hue=col, multiple='stack', ax=ax, bins=20)\n    ax.set_title(f'Distribución de charges por {col}')\n    ax.set_xlabel('charges')\n    ax.set_ylabel('Frecuencia')\n\nplt.tight_layout();\n\n\n\npng\n\n\nDistribución de charges para cada variable categórica\n\n\n3 Tratamiento de valores outliers\nSe utilizo el metodo de Winsorizing\ndef winsorize_series(s, factor=1.5):\n    Q1, Q3 = s.quantile([0.25, 0.75])\n    IQR = Q3 - Q1\n    lower, upper = Q1 - factor * IQR, Q3 + factor * IQR\n    return s.clip(lower, upper)\n\ncols = [\"age\", \"bmi\", \"children\"]\n\ndf_original = df[cols].copy()\n\ndf_winsor = df_original.copy()\nfor col in cols:\n    df_winsor[col] = winsorize_series(df_original[col])\n\n\nfig, axes = plt.subplots(1, len(cols), figsize=(18, 5))\n\nfor i, col in enumerate(cols):\n    df_compare = pd.DataFrame({\n        \"Valores\": pd.concat([df_original[col], df_winsor[col]], ignore_index=True),\n        \"Estado\": [\"Original\"] * len(df_original) + [\"Winsorized\"] * len(df_winsor)\n    })\n\n    sns.boxplot(data=df_compare, x=\"Estado\", y=\"Valores\", hue=\"Estado\",\n                palette=\"Set2\", dodge=False, ax=axes[i])\n    axes[i].set_title(f\"{col} (Original vs Winsorized)\", fontsize=12)\n    axes[i].set_xlabel(col)\n\nplt.suptitle(\"Original vs Winsorizing \", fontsize=14)\nplt.tight_layout();\n\n\n\npng\n\n\nEl metodo winsorizing reduce los valores extremos y ayuda a reduce la dispersión\nsns.boxplot(data=df, y=\"charges\", hue=\"smoker\").set_title(\"Costo: Fumadores vs No Fumadores\");\n\n\n\npng\n\n\nExiste un desbalance el variable smoker, el cual se debe de tomar encuenta en el modelo\n\n\n4 Preprocesamiento\nnumericas = numericas[:-1]\n\nX = df.drop(\"charges\", axis=1)\ny = df[\"charges\"]\n\nfor col in numericas:\n    X[col] = winsorize_series(X[col])\n\npreproc = ColumnTransformer([\n    (\"num\", StandardScaler(), numericas),\n    (\"cat\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False), categoricas)\n])\n\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, random_state=42, stratify=df[\"smoker\"])\n\npreproc.fit(X_train)\nX_train_processed = preproc.transform(X_train)\nX_test_processed = preproc.transform(X_test)\nSe separo las columnas de la variable objetivo\nSe redujeron los valores outliers.\nSe reescalo la variables numericas.\nSe transformaron las variables categorias.\nSe dividio el dataset en 80% train y 20% test, se tomo encuenta en desbalance de la columna smoker, para tener una mejor distribución de los datos.\n\n\n5 Selección de los modelos\nmodelos = {\n    \"linreg\": LinearRegression(),\n    \"ridge\": Ridge(random_state=42),\n    \"lasso\": Lasso(random_state=42),\n    \"enet\": ElasticNet(random_state=42),\n    \"dt\": DecisionTreeRegressor(random_state=42),\n    \"rf\": RandomForestRegressor(random_state=42, n_jobs=-1),\n    \"gb\": GradientBoostingRegressor(random_state=42),\n    \"et\": ExtraTreesRegressor(random_state=42, n_jobs=-1),\n    \"hgb\": HistGradientBoostingRegressor(random_state=42),\n    \"knn\": KNeighborsRegressor(),\n    \"bayes_ridge\": BayesianRidge(),\n    \"ard\": ARDRegression()\n}\n\nresultados_default = {}\nfor name, modelo in modelos.items():\n    modelo.fit(X_train_processed, y_train)\n    y_pred = modelo.predict(X_test_processed)\n    resultados_default[name] = {\n        \"RMSE\": root_mean_squared_error(y_test, y_pred),\n        \"MAE\": mean_absolute_error(y_test, y_pred),\n        \"R2\": r2_score(y_test, y_pred),\n        \"MAPE\": np.mean(np.abs((y_test - y_pred) / y_test)) * 100\n    }\n\ndf_resultados = pd.DataFrame(resultados_default).round(3).transpose().sort_values(\"RMSE\")\n\nfrecuentistas = [n for n in df_resultados.index if n not in [\"bayes_ridge\", \"ard\"]]\nbayesianos = [\"bayes_ridge\", \"ard\"]\n\nprint(\"\\n--- Ranking Frecuentistas ---\")\nprint(df_resultados.loc[frecuentistas])\n--- Ranking Frecuentistas ---\n            RMSE       MAE     R2    MAPE\ngb      4275.516  2401.829  0.876  28.568\nhgb     4719.726  2856.109  0.849  37.770\nrf      4758.837  2811.406  0.846  37.836\net      5150.095  2746.673  0.820  40.756\nlasso   5578.435  3873.742  0.789  38.435\nridge   5578.495  3877.731  0.789  38.492\nlinreg  5578.582  3873.931  0.789  38.438\nknn     5964.791  3701.869  0.759  40.099\ndt      6022.786  2790.782  0.754  36.124\nenet    8278.938  6163.192  0.535  90.716\nSe entreno con varios modelos, tanto modelos frecuentistas como bayesianos y se hizo la comparacion con la metrica RMSE\nprint(\"\\n--- Top 3 Modelos Frecuentistas ---\")\nprint(df_resultados.loc[frecuentistas][:3].sort_values(\"RMSE\"))\n\nprint(\"\\n---------------\")\n\nprint(\"\\n--- Modelos Bayesianos ---\")\nprint(df_resultados.loc[bayesianos].sort_values(\"RMSE\"))\n--- Top 3 Modelos Frecuentistas ---\n         RMSE       MAE     R2    MAPE\ngb   4275.516  2401.829  0.876  28.568\nhgb  4719.726  2856.109  0.849  37.770\nrf   4758.837  2811.406  0.846  37.836\n\n---------------\n\n--- Modelos Bayesianos ---\n                 RMSE       MAE     R2    MAPE\nard          5575.852  3865.231  0.789  38.549\nbayes_ridge  5578.494  3877.773  0.789  38.493\nLos modelos frecuentistas selecionados por tener menor RMSE son:\n\nGradientBoostingRegressor\nHistGradientBoostingRegressor\nRandomForestRegressor\n\nLos modelos bayesianos selecionados por tener menor RMSE son:\n\nARDRegression\nBayesianRidge\n\n\n\n6 Tuning los top 3 modelos frecuencistas\nparam_grid = {\n    \"ridge\": {\"alpha\": [0.1, 1.0, 10.0]},\n    \"lasso\": {\"alpha\": [0.001, 0.01, 0.1, 1.0]},\n    \"enet\": {\"alpha\": [0.001, 0.01, 0.1], \"l1_ratio\": [0.2, 0.5, 0.8]},\n    \"dt\": {\"max_depth\": [None, 5, 10, 20]},\n    \"rf\": {\"n_estimators\": [200, 500], \"max_depth\": [None, 10, 20]},\n    \"gb\": {\"n_estimators\": [100, 200], \"learning_rate\": [0.05, 0.1]},\n    \"et\": {\"n_estimators\": [200, 500], \"max_depth\": [None, 10, 20]},\n    \"hgb\": {\"max_iter\": [200, 500], \"learning_rate\": [0.05, 0.1]},\n    \"knn\": {\"n_neighbors\": [5, 10, 15]},\n    \"bayes_ridge\": {\"alpha_1\": [1e-6, 1e-4], \"alpha_2\": [1e-6, 1e-4]},\n    \"ard\": {\"alpha_1\": [1e-6, 1e-4], \"alpha_2\": [1e-6, 1e-4]}\n}\n\nbest_models, best_params = {}, {}\ncv = KFold(n_splits=5, shuffle=True, random_state=42)\ntop3 = df_resultados.index[:3].tolist()\n\nfor name in top3:\n    if name not in param_grid:\n        best_models[name] = modelos[name].fit(X_train_processed, y_train)\n        best_params[name] = {}\n    else:\n        grid = GridSearchCV(modelos[name], param_grid[name], cv=cv,\n                            scoring=\"neg_root_mean_squared_error\", n_jobs=-1)\n        grid.fit(X_train_processed, y_train)\n        best_models[name] = grid.best_estimator_\n        best_params[name] = grid.best_params_\n\najustados = {}\nfor name, modelo in modelos.items():\n    if name in best_models:\n        ajustados[name] = best_models[name]\n    else:\n        modelo.fit(X_train_processed, y_train)\n        ajustados[name] = modelo\n\nscores_final = {\n    name: root_mean_squared_error(y_test, m.predict(X_test_processed))\n    for name, m in ajustados.items()\n}\n\nbest_frec_name = min(frecuentistas, key=lambda n: scores_final[n])\nbest_bayes_name = min(bayesianos, key=lambda n: scores_final[n])\n\nbest_frec_model = ajustados[best_frec_name]\nbest_bayes_model = ajustados[best_bayes_name]\nSe realizo un tuning de los top 3 modelos frecuentistas y bayesianos, y se selecciono el mejor de cada enfoque, luego se evaluo en el data test.\ny_pred_frec = best_frec_model.predict(X_test_processed)\ny_pred_bayes, _ = best_bayes_model.predict(X_test_processed, return_std=True)\n\nresult_frec = {\n    \"Modelo\": f\"Frecuentista {best_frec_name}\",\n    \"RMSE\": root_mean_squared_error(y_test, y_pred_frec),\n    \"MAE\": mean_absolute_error(y_test, y_pred_frec),\n    \"R2\": r2_score(y_test, y_pred_frec),\n    \"MAPE\": np.mean(np.abs((y_test - y_pred_frec) / y_test)) * 100  \n}\n\nresult_bayes = {\n    \"Modelo\": f\"Bayesiano {best_bayes_name}\",\n    \"RMSE\": root_mean_squared_error(y_test, y_pred_bayes),\n    \"MAE\": mean_absolute_error(y_test, y_pred_bayes),\n    \"R2\": r2_score(y_test, y_pred_bayes),\n    \"MAPE\": np.mean(np.abs((y_test - y_pred_bayes) / y_test)) * 100    \n}\n\ndf_resultados = pd.DataFrame([result_frec, result_bayes])\ndf_resultados.round(3)\n\n\n\n\n\n\n\n\nModelo\n\n\nRMSE\n\n\nMAE\n\n\nR2\n\n\nMAPE\n\n\n\n\n\n\n0\n\n\nFrecuentista gb\n\n\n4183.896\n\n\n2410.873\n\n\n0.881\n\n\n31.138\n\n\n\n\n1\n\n\nBayesiano ard\n\n\n5575.852\n\n\n3865.231\n\n\n0.789\n\n\n38.549\n\n\n\n\n\nLa mejores metricas de cada enfoque en el data test\ndef obtener_intervalos(model, X, y_true=None, bayesiano=False):\n    if bayesiano:\n        y_mean, y_std = model.predict(X, return_std=True)\n        return y_mean, y_mean - 1.96*y_std, y_mean + 1.96*y_std\n    y_pred = model.predict(X)\n    if hasattr(model, \"estimators_\") and hasattr(model, \"n_estimators\") and not model.__class__.__name__.startswith(\"GradientBoosting\"):\n        estimators = model.estimators_\n        if isinstance(estimators, np.ndarray):\n            estimators = estimators.ravel().tolist()\n        member_preds = np.stack([est.predict(X) for est in estimators], axis=1)\n        std_preds = member_preds.std(axis=1)\n        return y_pred, y_pred - 1.96*std_preds, y_pred + 1.96*std_preds\n    resid_std = np.std(y_true - y_pred)\n    return y_pred, y_pred - 1.96*resid_std, y_pred + 1.96*resid_std\n\ny_center_frec, ci_lower_frec, ci_upper_frec = obtener_intervalos(best_frec_model, X_test_processed, y_test, bayesiano=False)\ny_center_bayes, ci_lower_bayes, ci_upper_bayes = obtener_intervalos(best_bayes_model, X_test_processed, bayesiano=True)\nSe crean los intervalos de confianza/credibilidad de cada enfoque\n\n\n7 Gráficos\nValores reales vs los predichos de cada enfoque, con su respectivo intervalo de confianza/credibilidad\nsns.set_style(\"whitegrid\")\n\nplt.figure(figsize=(14,6))\n\n# Frecuentista\nplt.subplot(1,2,1)\nsns.scatterplot(x=y_test, y=y_center_frec, hue=X_test[\"smoker\"],\n                palette={\"yes\":\"tab:red\",\"no\":\"tab:blue\"}, alpha=0.6, s=35)\nplt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()],\n         color=\"black\", linestyle=\"--\", label=\"Línea identidad\")\norder_f = np.argsort(y_test.values)\nplt.fill_between(y_test.values[order_f], ci_lower_frec[order_f], ci_upper_frec[order_f],\n                 color=\"gray\", alpha=0.3, label=\"IC 95%\")\nplt.title(f\"Frecuentista: {best_frec_name}\")\nplt.xlabel(\"Valores reales\")\nplt.ylabel(\"Predicciones\")\nplt.legend()\n\n# Bayesiano\nplt.subplot(1,2,2)\nsns.scatterplot(x=y_test, y=y_center_bayes, hue=X_test[\"smoker\"],\n                palette={\"yes\":\"tab:red\",\"no\":\"tab:blue\"}, alpha=0.6, s=35)\nplt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()],\n         color=\"black\", linestyle=\"--\", label=\"Línea identidad\")\norder_b = np.argsort(y_test.values)\nplt.fill_between(y_test.values[order_b], ci_lower_bayes[order_b], ci_upper_bayes[order_b],\n                 color=\"gray\", alpha=0.3, label=\"IC 95% (credibilidad)\")\nplt.title(f\"Bayesiano: {best_bayes_name}\")\nplt.xlabel(\"Valores reales\")\nplt.ylabel(\"Predicciones\")\nplt.legend()\n\nplt.tight_layout();\n\n\n\npng\n\n\nSe observa que el modelo frecuentista predice mejor, ademas de ver que los no fumadores causan mayor problema para la prediccion por los valores outliers que tienen\nresid_frec = y_test.values - y_center_frec\nresid_bayes = y_test.values - y_center_bayes\nband_frec = (ci_upper_frec - y_center_frec)\nband_bayes = (ci_upper_bayes - y_center_bayes)\n\nplt.figure(figsize=(14,6))\n\n\nplt.subplot(1,2,1)\nsns.scatterplot(x=y_center_frec, y=resid_frec, hue=X_test[\"smoker\"],\n                palette={\"yes\":\"tab:red\",\"no\":\"tab:blue\"}, alpha=0.6, s=35)\nplt.axhline(0, color=\"black\", linestyle=\"--\", label=\"Cero\")\norder_rf = np.argsort(y_center_frec)\nplt.fill_between(y_center_frec[order_rf], -band_frec[order_rf], band_frec[order_rf],\n                 color=\"gray\", alpha=0.3, label=\"IC 95% aprox.\")\nplt.title(f\"Residuales Frecuentista: {best_frec_name}\")\nplt.xlabel(\"Predicciones\")\nplt.ylabel(\"Residuales\")\nplt.legend()\n\n\nplt.subplot(1,2,2)\nsns.scatterplot(x=y_center_bayes, y=resid_bayes, hue=X_test[\"smoker\"],\n                palette={\"yes\":\"tab:red\",\"no\":\"tab:blue\"}, alpha=0.6, s=35)\nplt.axhline(0, color=\"black\", linestyle=\"--\", label=\"Cero\")\norder_rb = np.argsort(y_center_bayes)\nplt.fill_between(y_center_bayes[order_rb], -band_bayes[order_rb], band_bayes[order_rb],\n                 color=\"gray\", alpha=0.3, label=\"IC 95% (credibilidad)\")\nplt.title(f\"Residuales Bayesiano: {best_bayes_name}\")\nplt.xlabel(\"Predicciones\")\nplt.ylabel(\"Residuales\")\nplt.legend()\n\nplt.tight_layout();\n\n\n\npng\n\n\nSe observa lo mismo con los gráficos de los residuos\n\n\n8 SHAP\nVaribles Explicativas para el modelo Frecuentista\nfeature_names = preproc.get_feature_names_out().tolist()\nexplainer_frec = shap.Explainer(best_frec_model, X_train_processed)\nshap_values_frec = explainer_frec(X_test_processed)\n\n\nplt.title(f\"SHAP Summary - {best_frec_name}\")\nshap.summary_plot(shap_values_frec, X_test_processed, feature_names=feature_names)\n\n\n\npng\n\n\nEl SHAP de gb muestra que la varible no fumadores tiene un gran impacto, seguido de los fumadores en la variable charges\nVaribles Explicativas para el modelo Bayesiano\nexplainer_bayes = shap.Explainer(best_bayes_model, X_train_processed)\nshap_values_bayes = explainer_bayes(X_test_processed)\n\nplt.title(f\"SHAP Summary - {best_bayes_name}\")\nshap.summary_plot(shap_values_bayes, X_test_processed, feature_names=feature_names)\n\n\n\npng\n\n\n\n\n9 Guardar modelo\nSe guarda el modelo el formato onnx para ser ejecutado en la web o móvil\nn_features = X_train_processed.shape[1]\ninitial_type = [('float_input', FloatTensorType([None, n_features]))]\n\nonnx_frec = convert_sklearn(best_frec_model,\n                            target_opset=13,  \n                            initial_types=initial_type)\nwith open(\"best_frec_model.onnx\", \"wb\") as f:\n    f.write(onnx_frec.SerializeToString())\n\nonnx_bayes = convert_sklearn(best_bayes_model, \n                             target_opset=13, \n                             initial_types=initial_type)\nwith open(\"best_bayes_model.onnx\", \"wb\") as f:\n    f.write(onnx_bayes.SerializeToString())\nVerificar si el modelo se guardo correctamente a traves de la introducción de un dato\nsess_frec = ort.InferenceSession(\"best_frec_model.onnx\")\nsess_bayes = ort.InferenceSession(\"best_bayes_model.onnx\")\n\nsample_input = X_test_processed[0:1].astype(np.float32)\ninput_name_frec = sess_frec.get_inputs()[0].name\ninput_name_bayes = sess_bayes.get_inputs()[0].name\n\npred_frec = sess_frec.run(None, {input_name_frec: sample_input})[0]\npred_bayes = sess_bayes.run(None, {input_name_bayes: sample_input})[0]\n\nprint(\"Predicción Frecuentista:\", pred_frec)\nprint(\"Predicción Bayesiana:\", pred_bayes)\n\nprint(\"Valor real de test:\", y_test.iloc[0])\nPredicción Frecuentista: [[8627.369]]\nPredicción Bayesiana: [[7778.1484]]\nValor real de test: 6799.458\nValores de las columnas X’s\nprint(\"Valor real de test:\\n\", X_test.iloc[0])\nValor real de test:\n age                31\nsex              male\nbmi              28.5\nchildren            5\nsmoker             no\nregion      northeast\nName: 71, dtype: object"
  }
]